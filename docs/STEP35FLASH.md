# Step-3.5-Flash Model Integration

Step-3.5-Flash æ˜¯ StepFun å¼€å‘çš„é«˜çº§å¤§è¯­è¨€æ¨¡å‹ï¼Œä¸“ä¸ºç”Ÿäº§çº§æ¨ç†å¼•æ“è®¾è®¡ã€‚

## ğŸš€ æ¨¡å‹ç‰¹æ€§

- **196B å‚æ•°æ€»é‡**ï¼Œä½†åªæœ‰ **11B æ¿€æ´»å‚æ•°**ï¼ˆç¨€ç– MoE ç»“æ„ï¼‰
- **å¤štokené¢„æµ‹æœºåˆ¶**ï¼Œæ¨ç†é€Ÿåº¦æ›´å¿«
- **å†…ç½®æ¨ç†å’Œå·¥å…·è°ƒç”¨èƒ½åŠ›**
- **ä¼˜åŒ–ç”¨äºä½å»¶è¿Ÿã€é«˜æ€§ä»·æ¯”çš„é•¿ä¸Šä¸‹æ–‡æ¨ç†**
- **æ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡**ï¼ˆæœ€å¤š 32768 tokensï¼‰

## ğŸ“‹ å¿«é€Ÿå¼€å§‹

### 1. ä½¿ç”¨ Docker å¯åŠ¨ Step-3.5-Flash æœåŠ¡

```bash
# å¯åŠ¨ FP16 ç‰ˆæœ¬ï¼ˆæ¨èï¼‰
docker-compose -f docker/docker-compose.step35flash.yml up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose -f docker/docker-compose.step35flash.yml logs -f

# åœæ­¢æœåŠ¡
docker-compose -f docker/docker-compose.step35flash.yml down
```

### 2. é…ç½® MemScreen ä½¿ç”¨ Step-3.5-Flash

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export MEMSCREEN_LLM_BACKEND=vllm
export MEMSCREEN_VLLM_URL=http://localhost:8001
export MEMSCREEN_VLLM_LLM_MODEL=stepfun-ai/Step-3.5-Flash

# å¯åŠ¨ MemScreen
python start.py
```

### 3. æµ‹è¯•æ¨¡å‹

```bash
# è¿è¡Œæµ‹è¯•è„šæœ¬
python test_step35flash.py
```

## ğŸ”§ é«˜çº§é…ç½®

### å¤š GPU éƒ¨ç½²

#### Tensor Parallel (TP) - é€‚åˆä½å»¶è¿Ÿåœºæ™¯
```bash
export TENSOR_PARALLEL_SIZE=4
docker-compose -f docker/docker-compose.step35flash.yml up -d
```

#### Data Parallel (DP) - é€‚åˆé«˜è´Ÿè½½åœºæ™¯
```yaml
# ä¿®æ”¹ docker/docker-compose.step35flash.yml
command: >
  --model stepfun-ai/Step-3.5-Flash
  --data-parallel-size 4
  --enable-expert-parallel
  --reasoning-parser step3p5
  --tool-call-parser step3p5
  --enable-auto-tool-choice
  --trust-remote-code
```

### FP8 é‡åŒ–ç‰ˆæœ¬ï¼ˆæ›´å¥½çš„å†…å­˜æ•ˆç‡ï¼‰

```bash
# å¯åŠ¨ FP8 ç‰ˆæœ¬
docker-compose --profile fp8 -f docker/docker-compose.step35flash.yml up -d
```

**æ³¨æ„**: FP8 ç‰ˆæœ¬ä¸æ”¯æŒ TP > 1

### GPU å†…å­˜åˆ©ç”¨ç‡è°ƒæ•´

```bash
export GPU_MEMORY_UTILIZATION=0.95
docker-compose -f docker/docker-compose.step35flash.yml up -d
```

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

åœ¨ 4x H200 (TP4 + FP16) ä¸Šçš„åŸºå‡†æµ‹è¯•ï¼š

- **è¯·æ±‚åå**: 0.79 req/s
- **è¾“å‡º token åå**: 811.94 tok/s
- **å³°å€¼ token åå**: 940.00 tok/s
- **å¹³å‡ TTFT**: 422.62 ms
- **å¹³å‡ TPOT**: 11.91 ms

## ğŸ¯ é€‚ç”¨åœºæ™¯

Step-3.5-Flash ç‰¹åˆ«é€‚åˆï¼š

1. **å¤æ‚æ¨ç†ä»»åŠ¡**
   - æ•°å­¦é—®é¢˜æ±‚è§£
   - é€»è¾‘æ¨ç†
   - å¤šæ­¥éª¤é—®é¢˜è§£å†³

2. **é•¿ä¸Šä¸‹æ–‡å¤„ç†**
   - é•¿æ–‡æ¡£åˆ†æ
   - ä»£ç ç†è§£
   - ä¸Šä¸‹æ–‡æ€»ç»“

3. **å·¥å…·è°ƒç”¨åœºæ™¯**
   - API è°ƒç”¨
   - å‡½æ•°æ‰§è¡Œ
   - è‡ªåŠ¨åŒ–å·¥ä½œæµ

4. **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²**
   - ä½å»¶è¿Ÿè¦æ±‚
   - é«˜å¹¶å‘è¯·æ±‚
   - æˆæœ¬æ•æ„Ÿåœºæ™¯

## ğŸ” æ¨¡å‹é€‰é¡¹

| æ¨¡å‹ | ç²¾åº¦ | æ˜¾å­˜éœ€æ±‚ | ç‰¹ç‚¹ |
|------|------|----------|------|
| `stepfun-ai/Step-3.5-Flash` | FP16 | ~400GB (4x GPU) | æ¨èï¼Œå¹³è¡¡æ€§èƒ½å’Œç²¾åº¦ |
| `stepfun-ai/Step-3.5-Flash-FP8` | FP8 | ~200GB | æ›´å¥½çš„å†…å­˜æ•ˆç‡ |
| `stepfun-ai/Step-3.5-Flash-Int4` | Int4 | ~100GB | vLLM æš‚ä¸æ”¯æŒ |

## ğŸ› æ•…éšœæ’é™¤

### 1. B200 GPU FP8 MoE é”™è¯¯

```bash
# è®¾ç½®ç¯å¢ƒå˜é‡
export VLLM_USE_FLASHINFER_MOE_FP8=0
```

### 2. æ˜¾å­˜ä¸è¶³

- ä½¿ç”¨ FP8 ç‰ˆæœ¬
- å‡å°‘ `max-model-len`
- å¢åŠ  `tensor-parallel-size`

### 3. è¿æ¥è¶…æ—¶

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:8001/health

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
docker logs memscreen-step35flash
```

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [vLLM å®˜æ–¹æ–‡æ¡£](https://docs.vllm.ai/)
- [StepFun å®˜æ–¹ç½‘ç«™](https://stepfun.com/)
- [æ¨¡å‹å¡ç‰‡](https://huggingface.co/stepfun-ai/Step-3.5-Flash)

## ğŸ¤ è´¡çŒ®

å¦‚æœé‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·ï¼š
- æäº¤ [GitHub Issue](https://github.com/smileformylove/MemScreen/issues)
- æŸ¥çœ‹ [Discussions](https://github.com/smileformylove/MemScreen/discussions)
