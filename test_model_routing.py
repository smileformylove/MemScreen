#!/usr/bin/env python3
"""
Test script to demonstrate intelligent model routing.
"""

from memscreen.llm.model_router import get_router, ComplexityAnalyzer, ModelTier

def test_routing():
    """Test the intelligent routing system."""
    print("=" * 70)
    print("ğŸ§  Intelligent Model Routing Test")
    print("=" * 70)
    print()

    # Sample available models
    available_models = [
        "gemma2:2b",         # Tiny
        "qwen2.5vl:3b",      # Small
        "llama3.2:3b",       # Small
        "qwen2:7b",          # Medium
        "gemma2:9b",         # Medium
        "qwen2.5:14b",       # Large
    ]

    # Create router
    router = get_router(available_models)

    # Test queries of different complexity levels
    test_queries = [
        # Greetings - should route to TINY tier
        ("ä½ å¥½", "Simple greeting"),
        ("Hi there!", "Simple greeting in English"),
        ("å—¨ï¼", "Casual greeting"),

        # Simple questions - should route to SMALL tier
        ("ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ", "Simple question"),
        ("ä»€ä¹ˆæ˜¯ Pythonï¼Ÿ", "Factual question"),
        ("å‡ ç‚¹äº†ï¼Ÿ", "Time query"),

        # Conversational - should route to SMALL tier
        ("ä½ è§‰å¾—æ€ä¹ˆæ ·ï¼Ÿ", "Opinion question"),
        ("å¯ä»¥å¸®åŠ©æˆ‘å—ï¼Ÿ", "Help request"),

        # Complex reasoning - should route to MEDIUM tier
        ("ä¸ºä»€ä¹ˆæˆ‘çš„ç¨‹åºè¿è¡Œæ…¢ï¼Ÿåˆ†æå¯èƒ½çš„åŸå› ", "Reasoning task"),
        ("æ€»ç»“ä¸€ä¸‹ä»Šå¤©çš„å·¥ä½œå†…å®¹", "Summary task"),
        ("å¯¹æ¯”ä¸¤ç§æ–¹æ³•çš„ä¼˜ç¼ºç‚¹", "Comparison task"),

        # Creative - should route to MEDIUM tier
        ("å¸®æˆ‘å†™ä¸€å°é‚®ä»¶", "Creative task"),
        ("åˆ›ä½œä¸€ä¸ªæ•…äº‹", "Creative writing"),

        # Very complex - should route to LARGE tier
        ("åˆ†ææ•´ä¸ªç³»ç»Ÿçš„æ¶æ„è®¾è®¡ï¼Œæ‰¾å‡ºæ€§èƒ½ç“¶é¢ˆå¹¶æä¾›ä¼˜åŒ–å»ºè®®", "Complex analysis"),
        ("æ·±å…¥ç ”ç©¶è¿™ä¸ªé—®é¢˜çš„æ ¹æœ¬åŸå› ï¼Œå¹¶ç»™å‡ºé•¿æœŸè§£å†³æ–¹æ¡ˆ", "Deep reasoning"),
    ]

    print("Testing intelligent model routing:")
    print("-" * 70)
    print()

    for query, description in test_queries:
        # Get route
        model, config = router.route(query)
        analysis = router.analyzer.analyze(query)

        print(f"ğŸ“ Query: {query}")
        print(f"   Type: {description}")
        print(f"   â†’ Selected Model: {model}")
        print(f"   â†’ Tier: {config.tier.value}")
        print(f"   â†’ Complexity Score: {analysis.complexity_score:.2f}/1.0")
        print(f"   â†’ Est. Latency: {config.avg_latency_ms}ms")
        print(f"   â†’ Quality Score: {config.quality_score:.2f}")
        print()

    print("=" * 70)
    print("âœ… Routing test completed!")
    print("=" * 70)
    print()

    # Show tier distribution
    print("Model Tier Distribution:")
    print("-" * 70)
    for tier in [ModelTier.TINY, ModelTier.SMALL, ModelTier.MEDIUM, ModelTier.LARGE]:
        models = router.tier_models.get(tier, [])
        print(f"{tier.value.upper():8} tier: {len(models)} models")
        for model in models:
            config = router.model_configs.get(model)
            if config:
                print(f"           - {model:25} (quality: {config.quality_score:.2f}, latency: {config.avg_latency_ms}ms)")
        print()

    print()
    print("ğŸ’¡ Key Benefits:")
    print("  â€¢ Fast responses for simple queries (270M-1B models)")
    print("  â€¢ Balanced performance for daily tasks (1B-3B models)")
    print("  â€¢ High quality for complex questions (3B-7B models)")
    print("  â€¢ Best-in-class for reasoning tasks (7B+ models)")
    print("  â€¢ Automatic selection - no manual switching needed!")
    print()


def test_query_analysis():
    """Test the complexity analyzer."""
    print("=" * 70)
    print("ğŸ” Query Complexity Analysis")
    print("=" * 70)
    print()

    analyzer = ComplexityAnalyzer()

    test_cases = [
        ("ä½ å¥½ï¼", "Simple greeting"),
        ("æ˜¨å¤©æˆ‘çœ‹åˆ°ä¸€ä¸ªæœ‰è¶£çš„è§†é¢‘ï¼Œé‡Œé¢è®²åˆ°äº†äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹ã€‚", "Contextual statement"),
        ("ä¸ºä»€ä¹ˆæˆ‘çš„ä»£ç è¿è¡Œè¿™ä¹ˆæ…¢ï¼Ÿè¯·åˆ†æå¯èƒ½çš„åŸå› å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚", "Complex reasoning"),
        ("å¸®æˆ‘å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—", "Creative task"),
        ("è¯·æœç´¢æ‰€æœ‰åŒ…å«'Python'çš„æ–‡ä»¶", "Command"),
        ("ä»€ä¹ˆæ˜¯APIï¼Ÿ", "Factual question"),
        ("å¯¹æ¯”ä¸€ä¸‹ Python å’Œ JavaScript çš„ä¼˜ç¼ºç‚¹", "Comparison task"),
    ]

    for query, description in test_cases:
        analysis = analyzer.analyze(query)

        print(f"Query: {query}")
        print(f"Type: {description}")
        print(f"Complexity: {analysis.complexity_score:.2f}/1.0")
        print(f"Tier: {analysis.tier.value}")
        print(f"Characteristics:")
        print(f"  - Greeting: {analysis.is_greeting}")
        print(f"  - Question: {analysis.is_question}")
        print(f"  - Command: {analysis.is_command}")
        print(f"  - Conversational: {analysis.is_conversational}")
        print(f"  - Reasoning required: {analysis.reasoning_required}")
        print(f"  - Creative required: {analysis.creative_required}")
        print(f"  - Factual required: {analysis.factual_required}")
        print(f"  - Keywords: {', '.join(analysis.keywords)}")
        print(f"  - Est. tokens: {analysis.estimated_tokens:.0f}")
        print("-" * 70)
        print()


if __name__ == "__main__":
    print("\nğŸš€ MemScreen Intelligent Model Routing Demo")
    print("Testing smart model selection based on query complexity...\n")

    try:
        # Test routing
        test_routing()

        # Test analysis
        test_query_analysis()

        print("=" * 70)
        print("âœ… All tests completed successfully!")
        print("=" * 70)
        print()
        print("ğŸ“Š Summary:")
        print("  The intelligent routing system automatically selects the best model")
        print("  based on query complexity, ensuring fast yet high-quality responses.")
        print()

    except Exception as e:
        print(f"\nâŒ Test failed with error: {e}")
        import traceback
        traceback.print_exc()
