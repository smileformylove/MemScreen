#!/bin/bash
set -e

echo "=========================================="
echo "ðŸ¦‰ MemScreen Docker å¯åŠ¨è„šæœ¬"
echo "=========================================="

# 1. Start Xvfb (virtual display server)
echo "ðŸ“º å¯åŠ¨è™šæ‹Ÿæ˜¾ç¤ºæœåŠ¡å™¨..."
Xvfb :99 -screen 0 1920x1080x24 > /dev/null 2>&1 &
XVFB_PID=$!
sleep 2

# 2. Start fluxbox (window manager)
echo "ðŸ–¥ï¸ å¯åŠ¨çª—å£ç®¡ç†å™¨..."
fluxbox > /dev/null 2>&1 &
sleep 2

# 3. Start Ollama in background
echo "ðŸ¤– å¯åŠ¨ Ollama æœåŠ¡..."
ollama serve > /tmp/ollama.log 2>&1 &
OLLAMA_PID=$!
sleep 5

# Check if Ollama is running
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âš ï¸ Ollama å¯åŠ¨å¤±è´¥ï¼Œæ£€æŸ¥æ—¥å¿—ï¼š"
    cat /tmp/ollama.log
    exit 1
fi

echo "âœ… Ollama æœåŠ¡å·²å¯åŠ¨"

# 4. Pull models if not present
echo "ðŸ“¥ æ£€æŸ¥ AI æ¨¡åž‹..."

if ! ollama list | grep -q "qwen2.5vl:3b"; then
    echo "   ä¸‹è½½ qwen2.5vl:3b (~2GB)..."
    ollama pull qwen2.5vl:3b
fi

if ! ollama list | grep -q "mxbai-embed-large"; then
    echo "   ä¸‹è½½ mxbai-embed-large (~470MB)..."
    ollama pull mxbai-embed-large
fi

echo "âœ… AI æ¨¡åž‹å·²å°±ç»ª"

# 5. Start MemScreen application
echo "ðŸš€ å¯åŠ¨ MemScreen åº”ç”¨..."
cd /app

echo ""
echo "=========================================="
echo "âœ… MemScreen å·²å¯åŠ¨ï¼"
echo "=========================================="
echo ""
echo "ðŸ“ å¯ç”¨å‘½ä»¤:"
echo "  - è¿›å…¥å®¹å™¨: docker exec -it memscreen-app bash"
echo "  - æŸ¥çœ‹æ—¥å¿—: docker logs -f memscreen-app"
echo "  - åœæ­¢æœåŠ¡: docker-compose down"
echo ""
echo "ðŸŒ å¦‚æžœå¯ç”¨äº† noVNC:"
echo "  - è®¿é—®: http://localhost:6080"
echo ""
echo "ðŸ¦‰ å¯åŠ¨ MemScreen åº”ç”¨..."
echo "=========================================="

# Start the application
python start.py

# Cleanup on exit
trap "kill $XVFB_PID $OLLAMA_PID 2>/dev/null" EXIT
