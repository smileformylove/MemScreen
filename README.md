<div align="center">

  <!-- Main Logo -->
  <img src="assets/logo.png" alt="MemScreen Logo" width="280"/>

  # ğŸ¦‰ MemScreen

  ### **AI-Powered Visual Memory. 100% Private.**

  <br/>

  [![Product Hunt](https://img.shields.io/badge/Product%20Hunt-Featured-orange?style=for-the-badge&logo=producthunt&logoColor=white&labelColor=FF6154)](https://www.producthunt.com/products/memscreen)
  [![ShipIt](https://img.shields.io/badge/ShipIt-Published-purple?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIj48cGF0aCBkPSJNMTIgMmwwIDdjMi42NyAwIDguMTYgMS4zNCA4IDl2MmMwIDUuNjItNS4zMyA4LTggOGwwLTd6Ii8+PHBhdGggZD0iTTEyIDdsNSA1djZoLTEweiIvPjwvc3ZnPg==&logoColor=white&labelColor=9B59B6)](https://www.shipit.buzz/products/memscreen)
  [![NXGenTools](https://img.shields.io/badge/NXGenTools-Published-blue?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIj48cGF0aCBkPSJNMTIgMmwwIDdjMi42NyAwIDguMTYgMS4zNCA4IDl2MmMwIDUuNjItNS4zMyA4LTggOGwwLTd6Ii8+PC9zdmc+&logoColor=white&labelColor=4285F4)](https://www.nxgntools.com/tools/memscreen)
  [![100% Local](https://img.shields.io/badge/AI-100%25%20Local-success?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIj48cGF0aCBkPSJNMTIgMjJyczMtOSA5LTktOS05IDkgOS05IDkgOS05IDkgOS05IDkgOSA5LTkgOSA5IDkgOX0iLz48cGF0aCBkPSJNMTIgOHY4Ii8+PHBhdGggZD0iTTEyIDE2aDgiLz48L3N2Zz4=&logoColor=white&labelColor=06D6A0)](https://github.com/smileformylove/MemScreen)
  [![No Cloud](https://img.shields.io/badge/Privacy-No%20Cloud-blue?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIj48cGF0aCBkPSJNMTggMTB2LTRINnY0bTQgNmgtNHY0aDZhMiAyIDAgMCAwIDItMlYyYTIgMiAwIDAgMC0yLTJoLTJ6TDMgMTFWNGEyIDIgMCAwIDEgMi0yaDJIOUkiLz48L3N2Zz4=&logoColor=white&labelColor=457B9D)](https://github.com/smileformylove/MemScreen)
  [![GitHub Stars](https://img.shields.io/github/stars/smileformylove/MemScreen?style=for-the-badge&logo=github&logoColor=white&labelColor=333&color=blue)](https://github.com/smileformylove/MemScreen/stargazers)
  [![License](https://img.shields.io/badge/license-MIT-blue?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiPjxwYXRoIGQ9Ik0xMCAyMEgyMm0tOCAwaDgiLz48cGF0aCBkPSJNOSAxOWg2Ii8+PHBhdGggZD0iTTEwIDVoNG0tMiAwaDQiLz48L3N2Zz4=)](LICENSE)
  [![Python](https://img.shields.io/badge/python-3.8+-green?style=for-the-badge&logo=python&logoColor=white&labelColor=333)](https://www.python.org/downloads/)
  [![Ollama](https://img.shields.io/badge/ollama-supported-orange?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIj48cGF0aCBkPSJNMTIgMmwwIDdjMi42NyAwIDguMTYgMS4zNCA4IDl2MmMwIDUuNjItNS4zMyA4LTggOGwwLTd6Ii8+PC9zdmc+)](https://ollama.com)
  [![vLLM](https://img.shields.io/badge/vLLM-supported-blue?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIj48cGF0aCBkPSJNMTIgMmwwIDdjMi42NyAwIDguMTYgMS4zNCA4IDl2MmMwIDUuNjItNS4zMyA4LTggOGwwLTd6Ii8+PHBhdGggZD0iTTEyIDdsNSA1djZoLTEweiIvPjwvc3ZnPg==)](https://docs.vllm.ai/)
  [![Version](https://img.shields.io/badge/version-v0.5.0-brightgreen?style=for-the-badge&logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgZmlsbD0ibm9uZSIgc3Ryb2tlPSJ3aGl0ZSIgc3Ryb2tlLXdpZHRoPSIyIj48Y2lyY2xlIGN4PSIxMiIgY3k9IjEyIiByPSIxMCIvPjxwYXRoIGQ9Ik0xMiA2djZsNCAzIi8+PC9zdmc+&labelColor=333)](https://github.com/smileformylove/MemScreen/releases/tag/v0.5.0)

  **100% Local â€¢ 100% Private â€¢ AI-Powered Visual Memory System**

  [âš¡ Quick Start](#-quick-start) â€¢ [âœ¨ Features](#-features) â€¢ [ğŸ¬ Demo](#interface-preview) â€¢ [ğŸ“– Documentation](#-documentation)

</div>

---

## âœ¨ What is MemScreen?

<div align="center">

  <img src="assets/logo_medium.png" alt="MemScreen" width="120"/>

</div>

**MemScreen** is your personal AI-powered visual memory system that captures, understands, and remembers everything on your screen â€” **100% locally, 100% privately**.

### ğŸš€ The Problem

> Ever forgotten something you saw on your screen?
> - "What was that article about Python decorators I read yesterday?"
> - "Where did I see that UI mockup with the dark blue button?"
> - "What was that function I wrote last Tuesday?"

### ğŸ’¡ The Solution

**MemScreen** gives you a **photographic memory for your digital life**:
- ğŸ“¸ **Record** your screen continuously or on-demand
- ğŸ¤– **AI-powered understanding** with local vision models
- ğŸ” **Instant semantic search** across all your recordings
- ğŸ’¬ **Natural language queries** â€” just ask like you would a human
- ğŸ”’ **Zero privacy concerns** â€” everything runs locally on your machine

<div align="center">

  **ğŸ‰ Featured on Product Hunt, ShipIt & NXGenTools!**

  **[ğŸš€ Product Hunt](https://www.producthunt.com/products/memscreen)** â€” The best place to discover and launch new products

  **[ğŸš¢ ShipIt](https://www.shipit.buzz/products/memscreen)** â€” The launchpad for makers to reach early adopters

  **[ğŸ› ï¸ NXGenTools](https://www.nxgntools.com/tools/memscreen)** â€” Discover the best AI tools and resources

  **ğŸ‰ v0.5.0 â€” Enhanced Custom Region Recording & Clean UI!**

  - ğŸ¯ **Custom Region Selection** â€” Select any area of your screen to record
  - ğŸ“ **Visual Crosshair Guides** â€” Precise region selection with guide lines
  - ğŸ”„ **Re-selectable** â€” Change your selection as many times as needed
  - âœ¨ **Sleek Interface** â€” Clean, focused user experience with modern sidebar
  - ğŸ§¹ **Code Cleanup** â€” Removed unused files for better maintainability

  [View Changelog](https://github.com/smileformylove/MemScreen/compare/v0.4.0...v0.5.0)

</div>

---

## âš¡ Quick Start

<div align="center">

  <img src="assets/logo_medium.png" alt="Quick Start" width="100"/>

  **Get Started in 3 Minutes**

</div>

Get up and running in **3 minutes** â€” **no API keys, no cloud, no signup!**

### ğŸ³ Option 1: Docker (Recommended)

**Easiest way** - No dependencies to install!

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/smileformylove/MemScreen.git && cd MemScreen

# 2ï¸âƒ£ One-command start
docker-compose up -d

# 3ï¸âƒ£ Check logs
docker-compose logs -f memscreen
```

âœ… **Pros:** Auto-installs everything, isolated environment, easy cleanup
ğŸ“š **See:** [Docker Guide](docs/DOCKER.md) for advanced options

---

### ğŸ’» Option 2: Local Installation

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/smileformylove/MemScreen.git && cd MemScreen

# 2ï¸âƒ£ Install Ollama (local AI runtime)
brew install ollama        # macOS (visit ollama.com for Linux/Windows)

# 3ï¸âƒ£ Download AI Models (one-time, ~3GB)
ollama pull qwen2.5vl:3b          # Vision model (~2GB)
ollama pull mxbai-embed-large     # Text embeddings (~470MB)

# 4ï¸âƒ£ Install Python dependencies
pip install -r requirements.txt

# 5ï¸âƒ£ Launch MemScreen ğŸš€
python start.py
```

**That's it!** Start recording and searching your screen memory immediately.

> **ğŸ’¡ Pro Tip:** Once models are downloaded, MemScreen works **completely offline**. No internet needed.

---

## âœ¨ Features

<div align="center">

  <img src="assets/logo_small.png" alt="Features" width="50"/>

  **Comprehensive Screen Memory System**

</div>

### ğŸ¯ Screen Recording

- **ğŸ–¥ï¸ Full Screen Recording** â€” Capture everything on your screen
- **ğŸ“ Custom Region Recording** â€” Select specific areas to record
  - Drag-to-select with visual crosshair guides
  - Re-selectable until you start recording
  - Perfect for recording specific windows or areas
- **â±ï¸ Flexible Intervals** â€” Set capture frequency (0.5s - 5s)
- **ğŸ‘ï¸ Live Preview** â€” See exactly what's being captured

### ğŸ¤– AI-Powered Understanding

- **ğŸ§  Vision Intelligence** â€” Local MLLM (qwen2.5vl) understands your screen visually
- **ğŸ“ OCR Text Extraction** â€” Extract text from any screen content
- **ğŸ¨ Scene Recognition** â€” Identifies applications, activities, and UI elements
- **ğŸ” Semantic Search** â€” Find anything by meaning, not just keywords

### ğŸ¯ Intelligent Agent (New!)

- **âš¡ Auto Input Classification** â€” Automatically recognizes 15 input types (questions, tasks, code, procedures, etc.)
- **ğŸ¯ Query Intent Recognition** â€” Identifies 7 query intents for intelligent routing
- **ğŸ¤– Smart Dispatch System** â€” Automatically routes to the best handler without manual coding
- **ğŸš€ 3-5x Faster** â€” Category-based routing dramatically speeds up responses
- **ğŸ’° 70% Fewer Tokens** â€” Targeted context retrieval reduces API usage

### ğŸ“Š Dynamic Memory System

- **ğŸ—‚ï¸ Categorized Storage** â€” 15 memory categories for intelligent organization
- **ğŸ” Smart Search** â€” Search only relevant categories for faster results
- **ğŸ¯ Context Optimization** â€” Automatically retrieves the most relevant context
- **ğŸŒ Multi-Language Support** â€” Chinese and English input classification
- **ğŸ“ˆ Adaptive Learning** â€” Tracks usage patterns to optimize performance

### ğŸ’¬ Natural Language Chat

- **â“ Ask Questions** â€” "What was that article about Python I read yesterday?"
- **ğŸ“Š Summarize** â€” "Summarize all documentation I viewed this week"
- **ğŸ” Search** â€” "Find the UI mockup with the dark blue button"
- **ğŸ’¡ Smart Responses** â€” AI uses your screen memory to answer accurately

### ğŸ”’ Privacy First

- **âœ… 100% Local** â€” All AI processing happens on your machine
- **ğŸš« No Cloud** â€” No data sent to external servers
- **ğŸ” No API Keys** â€” Works out of the box
- **ğŸ“– Open Source** â€” Verify the code yourself

### ğŸ“Š Memory Sources

MemScreen builds comprehensive memory through **three integrated sources**:

1. **ğŸ“¸ Screen Recordings** â€” Primary source with OCR and scene understanding
2. **âŒ¨ï¸ Process Mining** â€” Keyboard/mouse tracking and activity patterns
3. **ğŸ’¬ Chat History** â€” Your conversations and queries

---

## ğŸ¬ Interface Preview

<div align="center">

  <img src="assets/logo_small.png" alt="MemScreen Icon" width="60"/>

  **Your AI-Powered Visual Memory**

</div>

### ğŸ”´ Recording Tab

Choose your recording mode and start capturing:

- **ğŸ–¥ï¸ Full Screen** â€” Record everything on your display
- **ğŸ“ Custom Region** â€” Select specific areas to record
  - Drag to select with visual crosshair guides
  - Press **ESC** to cancel, or reselect as needed
  - Click **"Start Recording"** when ready
- **ğŸ‘ï¸ Live Preview** â€” See what's being captured in real-time
- **ğŸ“ˆ Real-time Stats** â€” Frame count and elapsed time

### ğŸ’¬ AI Chat Tab

Ask questions and get intelligent answers:

- **ğŸ’­ Natural Questions** â€” Just type like you're asking a person
- **ğŸ” Memory Search** â€” AI searches all your recordings automatically
- **ğŸ¯ Context-Aware** â€” Uses OCR and scene understanding for accuracy
- **ğŸ“Š Rich Responses** â€” Detailed answers with specific references

### ğŸ¬ Videos Tab

Browse your recordings with intuitive timeline navigation:

- **ğŸ“… Visual Timeline** â€” See all your recordings at a glance
- **ğŸ¯ Video Markers** â€” Purple dots show when recordings were made
- **â–¶ï¸ Playback Controls** â€” Play, pause, seek through videos
- **ğŸ“Š Frame Navigation** â€” Jump to any moment instantly

---

## ğŸ“¦ Installation

<div align="center">

  <img src="assets/logo_medium.png" alt="Install" width="100"/>

  **Get Started in Minutes**

</div>

### ğŸ macOS (Recommended)

**Prerequisites:**
- macOS 11+ (Big Sur or later)
- Python 3.8 or higher
- 5GB free disk space

```bash
# Step 1: Install Ollama
brew install ollama

# Step 2: Start Ollama service
ollama serve
# Keep this terminal open, or press Ctrl+Z and type 'bg'

# Step 3: Pull AI Models (one-time)
ollama pull qwen2.5vl:3b          # Vision model (~2GB)
ollama pull mxbai-embed-large     # Embeddings (~470MB)

# Step 4: Install MemScreen
git clone https://github.com/smileformylove/MemScreen.git
cd MemScreen
pip install -r requirements.txt

# Step 5: Launch
python start.py
```

### ğŸ§ Linux / ğŸªŸ Windows

```bash
# Install Ollama from https://ollama.com/download
# Pull AI models
ollama pull qwen2.5vl:3b
ollama pull mxbai-embed-large

# Install MemScreen
git clone https://github.com/smileformylove/MemScreen.git
cd MemScreen
pip install -r requirements.txt

# Launch
python start.py
```

---

## ğŸ“– Documentation

For detailed documentation, see:
- [Docker Deployment](docs/DOCKER.md) â€” Containerized deployment guide
- [vLLM Backend](docs/VLLM_BACKEND.md) â€” High-performance inference backend setup
- [Step-3.5-Flash Model](docs/STEP35FLASH.md) â€” Advanced reasoning model integration
- [Architecture Overview](docs/ARCHITECTURE.md) â€” System design and components
- [Intelligent Agent System](docs/INTELLIGENT_AGENT.md) â€” Auto-classification and smart dispatch
- [Dynamic Memory System](docs/DYNAMIC_MEMORY.md) â€” Categorized memory and intelligent search
- [Testing Guide](docs/TESTING_GUIDE.md) â€” How to test the system
- [Quick Start Guide](docs/QUICK_START_GUIDE.py) â€” Interactive setup tutorial
- [Logo & Brand Guidelines](docs/LOGO_GUIDELINES.md) â€” Logo usage and branding

---

## ğŸ†š Why MemScreen?

<div align="center">

  <img src="assets/logo_small.png" alt="Why MemScreen" width="60"/>

  **See Why Users Choose MemScreen**

</div>

| Feature | MemScreen | OBS | Loom | CleanShot X |
|---------|-----------|-----|------|-------------|
| **Privacy** | âœ… **100% Local** | âœ… Local | âŒ Cloud | âœ… Local |
| **AI Understanding** | âœ… **Local MLLM** | âŒ No | âœ… Cloud AI | âŒ OCR only |
| **Semantic Search** | âœ… **Yes** | âŒ No | âŒ No | âŒ No |
| **Natural Language** | âœ… **Yes** | âŒ No | âŒ No | âŒ No |
| **Custom Region** | âœ… **Yes** | âœ… Yes | âŒ No | âœ… Yes |
| **Process Mining** | âœ… **Yes** | âŒ No | âŒ No | âŒ No |
| **Open Source** | âœ… **MIT** | âœ… GPL | âŒ No | âŒ No |
| **Cost** | **Free Forever** | Free | $15-30/mo | Paid |

### ğŸ”’ Privacy Guarantee

```
âŒ Other AI Tools:
   Screenshot â†’ Upload to Cloud â†’ Process â†’ Return Result
   âš ï¸ Your data on their servers âš ï¸

âœ… MemScreen:
   Screenshot â†’ Process Locally â†’ Result
   ğŸ”’ Your data stays with you ğŸ”’
```

---

## ğŸ› ï¸ Tech Stack

<div align="center">

  <img src="assets/logo_small.png" alt="Tech Stack" width="50"/>

  **Built with Privacy-First Technologies**

</div>

| Component | Technology | Privacy |
|-----------|------------|----------|
| **GUI Framework** | Kivy | âœ… Local |
| **Screen Capture** | PIL ImageGrab | âœ… Local |
| **Video Processing** | OpenCV | âœ… Local |
| **Databases** | SQLite + ChromaDB | âœ… Local |
| **AI Inference Backends** | Ollama / vLLM | âœ… **100% Local** |
| **Vision Models** | qwen2.5vl:3b / Qwen2-VL | âœ… **100% Local** |
| **Advanced Reasoning** | Step-3.5-Flash (optional) | âœ… **100% Local** |
| **Language** | Python 3.8+ | âœ… Local |

---

## ğŸ§  AI Inference Backends

<div align="center">

  <img src="assets/logo_medium.png" alt="AI Backends" width="100"/>

  **Flexible Inference Options**

</div>

MemScreen supports **multiple local AI inference backends** for different use cases:

### ğŸ¦™ Ollama (Default)

**Best for:** Development, local testing, users without dedicated GPUs

- âœ… **Easy setup** â€” One-command installation
- âœ… **Mac-friendly** â€” Runs on macOS without GPU
- âœ… **Low resource usage** â€” ~4GB RAM
- âœ… **Good models** â€” qwen2.5vl:3b (vision), mxbai-embed-large (embeddings)

**Setup:**
```bash
# Install Ollama
brew install ollama  # macOS

# Pull models
ollama pull qwen2.5vl:3b
ollama pull mxbai-embed-large

# Start MemScreen
python start.py
```

### âš¡ vLLM (Production)

**Best for:** Production deployments, high throughput, GPU acceleration

- âœ… **High performance** â€” PagedAttention for efficient memory management
- âœ… **OpenAI-compatible API** â€” Drop-in replacement for cloud APIs
- âœ… **GPU optimized** â€” Tensor parallelism for multi-GPU setups
- âœ… **Production-ready** â€” Used by enterprises for inference at scale

**Models:**
- **LLM:** Qwen/Qwen2.5-7B-Instruct (default)
- **Vision:** Qwen/Qwen2-VL-7B-Instruct
- **Embeddings:** intfloat/e5-mistral-7b-instruct

**Setup:**
```bash
# Install vLLM (optional dependency)
pip install 'memscreen[vllm]'

# Start vLLM server with Docker
docker-compose -f docker-compose.vllm.yml up -d

# Configure MemScreen to use vLLM
export MEMSCREEN_LLM_BACKEND=vllm
export MEMSCREEN_VLLM_URL=http://localhost:8000

# Start MemScreen
python start.py
```

**Hardware Requirements:**
- GPU: NVIDIA GPU with 12GB+ VRAM (for 7B models)
- CPU: Modern multi-core processor
- RAM: 16GB+ recommended

### ğŸš€ Step-3.5-Flash (Advanced Reasoning)

**Best for:** Complex reasoning tasks, mathematical problem solving, multi-step logic

- âœ… **196B parameters** â€” Only 11B active (sparse MoE)
- âœ… **Multi-token prediction** â€” Faster inference
- âœ… **Built-in reasoning** â€” Optimized for complex logic
- âœ… **Tool calling** â€” Native function execution support

**Setup:**
```bash
# Requires 4x H200/H20/B200 GPUs (~400GB VRAM for FP16)

# Start Step-3.5-Flash server
docker-compose -f docker-compose.step35flash.yml up -d

# Configure MemScreen
export MEMSCREEN_LLM_BACKEND=vllm
export MEMSCREEN_VLLM_URL=http://localhost:8001
export MEMSCREEN_VLLM_LLM_MODEL=stepfun-ai/Step-3.5-Flash

# Start MemScreen
python start.py
```

**Hardware Requirements:**
- GPU: 4x NVIDIA H200/H20/B200 (recommended)
- VRAM: ~400GB for FP16, ~200GB for FP8
- Alternative: Use FP8 version with 2x GPUs

See [Step-3.5-Flash Documentation](docs/STEP35FLASH.md) for details.

### ğŸ”„ Switching Backends

Easily switch between backends using environment variables:

```bash
# Use Ollama (default)
export MEMSCREEN_LLM_BACKEND=ollama

# Use vLLM with standard models
export MEMSCREEN_LLM_BACKEND=vllm
export MEMSCREEN_VLLM_URL=http://localhost:8000

# Use vLLM with Step-3.5-Flash
export MEMSCREEN_LLM_BACKEND=vllm
export MEMSCREEN_VLLM_URL=http://localhost:8001
export MEMSCREEN_VLLM_LLM_MODEL=stepfun-ai/Step-3.5-Flash
```

### ğŸ“Š Backend Comparison

| Feature | Ollama | vLLM (Standard) | vLLM (Step-3.5-Flash) |
|---------|--------|-----------------|----------------------|
| **Setup Difficulty** | â­ Easy | â­â­ Medium | â­â­â­ Hard |
| **Hardware Requirements** | CPU/GPU | GPU (12GB+) | 4x GPU (200GB+) |
| **Performance** | Good | Excellent | Outstanding |
| **Model Size** | 3B | 7B | 196B (11B active) |
| **Reasoning** | Basic | Good | Advanced |
| **Best For** | Development | Production | Complex Tasks |

---

## ğŸ“ What's New

### âœ¨ v0.5.0 â€” Dynamic Memory System & Intelligent Agent (February 2026)

**ğŸ¤– Intelligent Agent System:**
- **Auto Input Classification** â€” Automatically recognizes 15 input types (questions, tasks, code, procedures, etc.)
- **Query Intent Recognition** â€” Identifies 7 query intents for intelligent routing
- **Smart Dispatch System** â€” Automatically routes to the best handler without manual if-else
- **3-5x Performance Boost** â€” Category-based routing dramatically speeds up responses
- **70% Token Reduction** â€” Targeted context retrieval reduces API usage

**ğŸ“Š Dynamic Memory System:**
- **15 Memory Categories** â€” Intelligent organization (question, task, fact, code, procedure, etc.)
- **7 Query Intents** â€” retrieve_fact, find_procedure, search_conversation, locate_code, etc.
- **Smart Search** â€” Search only relevant categories for faster, more accurate results
- **Context Optimization** â€” Automatically retrieves the most relevant context for responses
- **Multi-Language Support** â€” Chinese and English pattern-based classification

**ğŸ¯ Custom Region Recording:**
- **Custom Region Selection** â€” Select specific screen areas to record
- **Visual Crosshair Guides** â€” Guide lines extend to screen edges for precision
- **Re-selectable Regions** â€” Change selection as many times as needed
- **Left Sidebar Navigation** â€” Modern, accessible UI design

**ğŸ”§ Code Improvements:**
- Removed duplicate and unused files
- Better button sizing and layout optimization
- Cleaner project structure
- Enhanced documentation

### âœ¨ v0.4.0 â€” Local AI Agent & Privacy-First Design

- ğŸ¤– **Local AI Agent System** â€” Task planning & skill execution
- ğŸ’¬ **Enhanced AI Chat** â€” Humanized, warm responses
- ğŸ”’ **Zero Cloud Dependencies** â€” No API keys, no data transmission

---

## ğŸ¤ Contributing

Contributions welcome! Here's how to help:

- ğŸ› Report bugs via [Issues](https://github.com/smileformylove/MemScreen/issues)
- ğŸ’¡ Suggest features via [Discussions](https://github.com/smileformylove/MemScreen/discussions)
- ğŸ“ Improve documentation
- ğŸ”§ Submit pull requests

---

## ğŸ“œ License

This project is released under the **MIT License** â€” free to use, modify, and distribute!

<div align="center">

  <img src="assets/logo_small.png" alt="MemScreen" width="80"/>

  **â­ Star us on GitHub â€” it helps the project grow!**

  [![Star](https://img.shields.io/github/stars/smileformylove/MemScreen?style=social)](https://github.com/smileformylove/MemScreen/stargazers)

  **Featured on [Product Hunt](https://www.producthunt.com/products/memscreen), [ShipIt](https://www.shipit.buzz/products/memscreen) & [NXGenTools](https://www.nxgntools.com/tools/memscreen)** â€” Discover and launch the best products

  Made with â¤ï¸ and ğŸ¦‰ by [Jixiang Luo](https://github.com/smileformylove)

  **v0.5.0** â€” Enhanced Custom Region Recording & Code Cleanup (January 2026)

  [ğŸ“§ Email](mailto:jixiangluo85@gmail.com) â€¢ [ğŸ› Report Bug](https://github.com/smileformylove/MemScreen/issues) â€¢ [ğŸ’¬ Discussion](https://github.com/smileformylove/MemScreen/discussions)

  ---

  **[ğŸ” Back to Top](#-memscreen)**

</div>
